{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "abfa8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623750cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in data provided by instructions\n",
    "url = 'https://github.com/ArinB/CA05-B-Logistic-Regression/raw/master/cvd_data.csv'\n",
    "data = pd.read_csv(url, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53cd4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvd_4types</th>\n",
       "      <th>age_s1</th>\n",
       "      <th>race</th>\n",
       "      <th>educat</th>\n",
       "      <th>mstat</th>\n",
       "      <th>hip</th>\n",
       "      <th>neck20</th>\n",
       "      <th>waist</th>\n",
       "      <th>av_weight_kg</th>\n",
       "      <th>cgpkyr</th>\n",
       "      <th>tea15</th>\n",
       "      <th>srhype</th>\n",
       "      <th>parrptdiab</th>\n",
       "      <th>bend25</th>\n",
       "      <th>happy25</th>\n",
       "      <th>tired25</th>\n",
       "      <th>hlthlm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>113.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>83.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>49.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>129.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>89.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>140.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>101.0</td>\n",
       "      <td>87.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>107.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>79.1</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>105.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>78.1</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>101.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>77.7</td>\n",
       "      <td>10.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>87.2</td>\n",
       "      <td>32.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>73.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>99.0</td>\n",
       "      <td>84.4</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>91.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>80.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>104.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>85.3</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>101.0</td>\n",
       "      <td>85.3</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>105.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>101.0</td>\n",
       "      <td>86.8</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>122.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>90.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>115.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>84.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>82.4</td>\n",
       "      <td>48.00</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>72.9</td>\n",
       "      <td>72.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.3</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>77.6</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>79.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cvd_4types  age_s1  race  educat  mstat    hip  neck20  waist  \\\n",
       "0            0      54     1       2      1  110.0    40.0  108.0   \n",
       "1            0      56     3       2      1  113.0    34.0  107.0   \n",
       "2            0      54     1       3      1  110.0    44.5  105.0   \n",
       "3            0      54     1       3      1  129.0    42.5  110.0   \n",
       "4            0      51     3       2      1  122.0    37.0  113.0   \n",
       "5            0      67     1       3      3  140.0    35.5  101.0   \n",
       "6            0      68     1       2      1  101.0    39.0   93.0   \n",
       "7            0      67     1       2      1  107.0    32.0   80.0   \n",
       "8            0      44     1       2      1  100.0    36.5   89.0   \n",
       "9            0      42     1       2      1  105.0    35.5   90.0   \n",
       "10           1      77     1       2      2  101.0    36.0   84.0   \n",
       "11           0      53     1       2      1  115.0    38.0  105.0   \n",
       "12           0      47     1       3      3   96.0    32.5   73.5   \n",
       "13           0      54     1       3      1  106.0    40.6   99.0   \n",
       "14           0      61     1       2      1  112.0    46.0  110.0   \n",
       "15           0      41     1       2      1  103.0    34.0   87.0   \n",
       "16           0      78     1       2      2  104.0    35.0   99.0   \n",
       "17           0      83     1       2      1  106.0    38.5  101.0   \n",
       "18           0      72     1       2      1  105.0    39.5  101.0   \n",
       "19           0      53     1       3      3  122.0    46.5  112.0   \n",
       "20           0      47     1       2      1  121.0    36.5   92.0   \n",
       "21           0      51     1       2      1  121.0    41.0  107.0   \n",
       "22           1      71     1       2      3  115.0    38.0   95.0   \n",
       "23           0      53     1       3      3  100.0    39.0   95.0   \n",
       "24           0      54     1       1      1   91.0    33.5   78.0   \n",
       "25           0      60     1       2      1  110.0    36.0   80.0   \n",
       "26           1      71     1       3      2   64.0    35.0   86.0   \n",
       "27           1      58     1       2      4  108.0    41.5  100.0   \n",
       "28           0      65     1       2      1  100.0    37.0   85.0   \n",
       "29           0      48     1       2      1  101.0    38.0   93.0   \n",
       "\n",
       "    av_weight_kg  cgpkyr  tea15  srhype  parrptdiab  bend25  happy25  tired25  \\\n",
       "0           87.5   34.00      0       1           0       1        2        3   \n",
       "1           83.5    0.00      0       0           0       2        2        1   \n",
       "2           86.2   49.50      0       0           0       3        2        6   \n",
       "3           89.1    0.00      0       0           0       3        2        1   \n",
       "4           81.3    0.00      0       0           0       2        1        1   \n",
       "5           87.2    0.00      0       1           0       1        1        4   \n",
       "6           80.5    9.20      0       0           0       2        3        4   \n",
       "7           73.2    0.00      0       1           0       2        2        4   \n",
       "8           79.1    6.75      0       0           0       3        3        4   \n",
       "9           78.1   21.00      0       0           0       3        2        3   \n",
       "10          77.7   10.50      0       1           0       3        2        5   \n",
       "11          87.2   32.80      1       0           0       3        2        4   \n",
       "12          76.0    0.00      2       0           0       3        2        6   \n",
       "13          84.4   34.00      0       1           0       3        2        4   \n",
       "14          91.4    0.00      2       1           0       2        2        5   \n",
       "15          80.3    0.00      1       0           0       3        4        4   \n",
       "16          85.3   20.00      1       1           0       2        4        4   \n",
       "17          85.3   14.00      0       0           0       2        2        5   \n",
       "18          86.8   11.00      0       0           0       1        2        4   \n",
       "19          90.0    0.00      0       0           0       2        2        2   \n",
       "20          80.6    0.00      0       0           0       3        1        4   \n",
       "21          90.8    0.00      0       0           0       2        3        2   \n",
       "22          84.5    0.00      1       0           0       2        2        4   \n",
       "23          82.4   48.00     21       0           0       3        2        5   \n",
       "24          72.9   72.00      0       0           0       3        2        4   \n",
       "25          73.3   40.00      0       0           0       2        2        4   \n",
       "26          77.6    7.35      0       1           0       3        2        5   \n",
       "27          84.5    0.00      0       0           0       3        4        4   \n",
       "28          79.9    0.00      2       1           0       3        2        5   \n",
       "29          78.0    1.50      0       0           0       3        2        4   \n",
       "\n",
       "    hlthlm25  \n",
       "0          4  \n",
       "1          3  \n",
       "2          4  \n",
       "3          3  \n",
       "4          2  \n",
       "5          4  \n",
       "6          4  \n",
       "7          4  \n",
       "8          4  \n",
       "9          3  \n",
       "10         4  \n",
       "11         4  \n",
       "12         4  \n",
       "13         4  \n",
       "14         4  \n",
       "15         4  \n",
       "16         3  \n",
       "17         4  \n",
       "18         4  \n",
       "19         4  \n",
       "20         4  \n",
       "21         3  \n",
       "22         2  \n",
       "23         4  \n",
       "24         4  \n",
       "25         3  \n",
       "26         4  \n",
       "27         4  \n",
       "28         4  \n",
       "29         4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dataset\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da634863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvd_4types</th>\n",
       "      <th>age_s1</th>\n",
       "      <th>race</th>\n",
       "      <th>educat</th>\n",
       "      <th>mstat</th>\n",
       "      <th>hip</th>\n",
       "      <th>neck20</th>\n",
       "      <th>waist</th>\n",
       "      <th>av_weight_kg</th>\n",
       "      <th>cgpkyr</th>\n",
       "      <th>tea15</th>\n",
       "      <th>srhype</th>\n",
       "      <th>parrptdiab</th>\n",
       "      <th>bend25</th>\n",
       "      <th>happy25</th>\n",
       "      <th>tired25</th>\n",
       "      <th>hlthlm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.590068</td>\n",
       "      <td>64.828809</td>\n",
       "      <td>1.094695</td>\n",
       "      <td>2.326342</td>\n",
       "      <td>1.368600</td>\n",
       "      <td>105.404832</td>\n",
       "      <td>37.550719</td>\n",
       "      <td>97.209904</td>\n",
       "      <td>82.945928</td>\n",
       "      <td>12.904010</td>\n",
       "      <td>0.430907</td>\n",
       "      <td>0.327884</td>\n",
       "      <td>0.067551</td>\n",
       "      <td>2.473782</td>\n",
       "      <td>2.281308</td>\n",
       "      <td>4.292721</td>\n",
       "      <td>3.864898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491897</td>\n",
       "      <td>10.400496</td>\n",
       "      <td>0.358237</td>\n",
       "      <td>0.697934</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>10.280402</td>\n",
       "      <td>4.101003</td>\n",
       "      <td>13.598060</td>\n",
       "      <td>7.849650</td>\n",
       "      <td>20.156736</td>\n",
       "      <td>1.242444</td>\n",
       "      <td>0.469515</td>\n",
       "      <td>0.251012</td>\n",
       "      <td>0.672158</td>\n",
       "      <td>0.951695</td>\n",
       "      <td>1.021099</td>\n",
       "      <td>0.614247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>57.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>34.425000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>78.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>37.150000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>82.550000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>86.575000</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>136.700000</td>\n",
       "      <td>170.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cvd_4types       age_s1         race       educat        mstat  \\\n",
       "count  3242.000000  3242.000000  3242.000000  3242.000000  3242.000000   \n",
       "mean      0.590068    64.828809     1.094695     2.326342     1.368600   \n",
       "std       0.491897    10.400496     0.358237     0.697934     0.933871   \n",
       "min       0.000000    39.000000     1.000000     1.000000     1.000000   \n",
       "25%       0.000000    57.000000     1.000000     2.000000     1.000000   \n",
       "50%       1.000000    65.000000     1.000000     2.000000     1.000000   \n",
       "75%       1.000000    73.000000     1.000000     3.000000     1.000000   \n",
       "max       1.000000    90.000000     3.000000     4.000000     8.000000   \n",
       "\n",
       "               hip       neck20        waist  av_weight_kg       cgpkyr  \\\n",
       "count  3242.000000  3242.000000  3242.000000   3242.000000  3242.000000   \n",
       "mean    105.404832    37.550719    97.209904     82.945928    12.904010   \n",
       "std      10.280402     4.101003    13.598060      7.849650    20.156736   \n",
       "min      44.000000    25.000000    67.000000     57.400000     0.000000   \n",
       "25%      99.000000    34.425000    88.000000     78.200000     0.000000   \n",
       "50%     104.000000    37.150000    97.000000     82.550000     0.300000   \n",
       "75%     110.000000    40.500000   106.000000     86.575000    20.475000   \n",
       "max     168.000000    53.000000   135.000000    136.700000   170.500000   \n",
       "\n",
       "             tea15       srhype   parrptdiab       bend25      happy25  \\\n",
       "count  3242.000000  3242.000000  3242.000000  3242.000000  3242.000000   \n",
       "mean      0.430907     0.327884     0.067551     2.473782     2.281308   \n",
       "std       1.242444     0.469515     0.251012     0.672158     0.951695   \n",
       "min       0.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "25%       0.000000     0.000000     0.000000     2.000000     2.000000   \n",
       "50%       0.000000     0.000000     0.000000     3.000000     2.000000   \n",
       "75%       0.000000     1.000000     0.000000     3.000000     3.000000   \n",
       "max      30.000000     1.000000     1.000000     3.000000     6.000000   \n",
       "\n",
       "           tired25     hlthlm25  \n",
       "count  3242.000000  3242.000000  \n",
       "mean      4.292721     3.864898  \n",
       "std       1.021099     0.614247  \n",
       "min       1.000000     1.000000  \n",
       "25%       4.000000     4.000000  \n",
       "50%       4.000000     4.000000  \n",
       "75%       5.000000     4.000000  \n",
       "max       6.000000     5.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65133b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cvd_4types      0\n",
       "age_s1          0\n",
       "race            0\n",
       "educat          0\n",
       "mstat           0\n",
       "hip             0\n",
       "neck20          0\n",
       "waist           0\n",
       "av_weight_kg    0\n",
       "cgpkyr          0\n",
       "tea15           0\n",
       "srhype          0\n",
       "parrptdiab      0\n",
       "bend25          0\n",
       "happy25         0\n",
       "tired25         0\n",
       "hlthlm25        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43cb1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep Data for Model\n",
    "X_Data = df.drop(columns='cvd_4types')\n",
    "Y_Data = df['cvd_4types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f13d5c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7667218151737177"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Model for Logistic Regression using parameters from lecture\n",
    "clf = linear_model.LogisticRegression(C=1e40 , solver='newton-cg', random_state=4, penalty = )\n",
    "fit_model = clf.fit(X_Data, Y_Data.values)\n",
    "fit_model.predict(X_Data.iloc[[22]])\n",
    "auc = metrics.roc_auc_score(Y_Data.values, fit_model.predict_proba(X_Data)[:,1])\n",
    "acc = metrics.accuracy_score(Y_Data, fit_model.predict(X_Data))\n",
    "f1 = metrics.f1_score(Y_Data, fit_model.predict(X_Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce2441",
   "metadata": {},
   "source": [
    "FOR LOOP THROUGH HYPER PARAMETERS TO FIND BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "30a1c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Lists for Hyperparameters\n",
    "C_List = [1,1e20,1e40]\n",
    "Solver_List = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "Penalty_List = ['l1','l2','elasticnet','none']\n",
    "\n",
    "#Create DataFrame to record results\n",
    "df_res = pd.DataFrame(columns=['C', 'Solver', 'Penalty', 'AUC', 'Accuracy', 'F1'], index=range(33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d98551e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "26\n",
      "27\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "#Generate for loop to cycle through all potential models (with exceptions) and record performance\n",
    "index = 0\n",
    "\n",
    "for solver in Solver_List:\n",
    "    for penalty in Penalty_List: #we block out the exceptions below for solvers that do not match with penalties\n",
    "        if ((solver == 'newton-cg' and penalty == 'l1') or (solver == 'newton-cg' and penalty == 'elasticnet') or\n",
    "        (solver == 'lbfgs' and penalty == 'l1') or (solver == 'lbfgs' and penalty == 'elasticnet') or\n",
    "        (solver == 'liblinear' and penalty == 'none') or (solver == 'liblinear' and penalty == 'elasticnet') or\n",
    "        (solver == 'sag' and penalty == 'l1') or (solver == 'sag' and penalty =='elasticnet') or (solver == 'saga' and penalty =='elasticnet')):\n",
    "            continue\n",
    "        for c in C_List:\n",
    "            clf = linear_model.LogisticRegression(C=c , solver=solver, penalty = penalty, random_state=4)\n",
    "            fit_model = clf.fit(X_Data, Y_Data.values)\n",
    "            auc = metrics.roc_auc_score(Y_Data.values, fit_model.predict_proba(X_Data)[:,1])\n",
    "            acc = metrics.accuracy_score(Y_Data, fit_model.predict(X_Data))\n",
    "            f1 = metrics.f1_score(Y_Data, fit_model.predict(X_Data))\n",
    "            df_res.iloc[index,0] = c\n",
    "            df_res.iloc[index,1] = solver\n",
    "            df_res.iloc[index,2] = penalty\n",
    "            df_res.iloc[index,3] = auc\n",
    "            df_res.iloc[index,4] = acc\n",
    "            df_res.iloc[index,5] = f1\n",
    "            index+= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8227d495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Solver</th>\n",
       "      <th>Penalty</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.719184</td>\n",
       "      <td>0.695867</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.719194</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.766722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.719194</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.766722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>none</td>\n",
       "      <td>0.719194</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.766722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>none</td>\n",
       "      <td>0.719194</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.766722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>none</td>\n",
       "      <td>0.719194</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.766722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.70397</td>\n",
       "      <td>0.685379</td>\n",
       "      <td>0.756911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.701361</td>\n",
       "      <td>0.689081</td>\n",
       "      <td>0.759312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.701361</td>\n",
       "      <td>0.689081</td>\n",
       "      <td>0.759312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>none</td>\n",
       "      <td>0.701361</td>\n",
       "      <td>0.689081</td>\n",
       "      <td>0.759312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>none</td>\n",
       "      <td>0.701361</td>\n",
       "      <td>0.689081</td>\n",
       "      <td>0.759312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>none</td>\n",
       "      <td>0.701361</td>\n",
       "      <td>0.689081</td>\n",
       "      <td>0.759312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.718034</td>\n",
       "      <td>0.69525</td>\n",
       "      <td>0.766541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.719158</td>\n",
       "      <td>0.69525</td>\n",
       "      <td>0.76643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.719158</td>\n",
       "      <td>0.69525</td>\n",
       "      <td>0.76643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.715243</td>\n",
       "      <td>0.690623</td>\n",
       "      <td>0.762379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.719165</td>\n",
       "      <td>0.694633</td>\n",
       "      <td>0.765847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.719173</td>\n",
       "      <td>0.69525</td>\n",
       "      <td>0.76643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.699917</td>\n",
       "      <td>0.683837</td>\n",
       "      <td>0.759784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.699948</td>\n",
       "      <td>0.683529</td>\n",
       "      <td>0.759606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.699948</td>\n",
       "      <td>0.683529</td>\n",
       "      <td>0.759606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>sag</td>\n",
       "      <td>none</td>\n",
       "      <td>0.699948</td>\n",
       "      <td>0.683529</td>\n",
       "      <td>0.759606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>sag</td>\n",
       "      <td>none</td>\n",
       "      <td>0.699948</td>\n",
       "      <td>0.683529</td>\n",
       "      <td>0.759606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>sag</td>\n",
       "      <td>none</td>\n",
       "      <td>0.699948</td>\n",
       "      <td>0.683529</td>\n",
       "      <td>0.759606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.69267</td>\n",
       "      <td>0.681986</td>\n",
       "      <td>0.758943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.758185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.758185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.692852</td>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.758185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.758185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.758185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>none</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.758185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>saga</td>\n",
       "      <td>none</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.758185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10000000000000000303786028427003666890752.0</td>\n",
       "      <td>saga</td>\n",
       "      <td>none</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.758185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              C     Solver Penalty       AUC  \\\n",
       "0                                             1  newton-cg      l2  0.719184   \n",
       "1                       100000000000000000000.0  newton-cg      l2  0.719194   \n",
       "2   10000000000000000303786028427003666890752.0  newton-cg      l2  0.719194   \n",
       "3                                             1  newton-cg    none  0.719194   \n",
       "4                       100000000000000000000.0  newton-cg    none  0.719194   \n",
       "5   10000000000000000303786028427003666890752.0  newton-cg    none  0.719194   \n",
       "6                                             1      lbfgs      l2   0.70397   \n",
       "7                       100000000000000000000.0      lbfgs      l2  0.701361   \n",
       "8   10000000000000000303786028427003666890752.0      lbfgs      l2  0.701361   \n",
       "9                                             1      lbfgs    none  0.701361   \n",
       "10                      100000000000000000000.0      lbfgs    none  0.701361   \n",
       "11  10000000000000000303786028427003666890752.0      lbfgs    none  0.701361   \n",
       "12                                            1  liblinear      l1  0.718034   \n",
       "13                      100000000000000000000.0  liblinear      l1  0.719158   \n",
       "14  10000000000000000303786028427003666890752.0  liblinear      l1  0.719158   \n",
       "15                                            1  liblinear      l2  0.715243   \n",
       "16                      100000000000000000000.0  liblinear      l2  0.719165   \n",
       "17  10000000000000000303786028427003666890752.0  liblinear      l2  0.719173   \n",
       "18                                            1        sag      l2  0.699917   \n",
       "19                      100000000000000000000.0        sag      l2  0.699948   \n",
       "20  10000000000000000303786028427003666890752.0        sag      l2  0.699948   \n",
       "21                                            1        sag    none  0.699948   \n",
       "22                      100000000000000000000.0        sag    none  0.699948   \n",
       "23  10000000000000000303786028427003666890752.0        sag    none  0.699948   \n",
       "24                                            1       saga      l1   0.69267   \n",
       "25                      100000000000000000000.0       saga      l1  0.692881   \n",
       "26  10000000000000000303786028427003666890752.0       saga      l1  0.692881   \n",
       "27                                            1       saga      l2  0.692852   \n",
       "28                      100000000000000000000.0       saga      l2  0.692881   \n",
       "29  10000000000000000303786028427003666890752.0       saga      l2  0.692881   \n",
       "30                                            1       saga    none  0.692881   \n",
       "31                      100000000000000000000.0       saga    none  0.692881   \n",
       "32  10000000000000000303786028427003666890752.0       saga    none  0.692881   \n",
       "\n",
       "    Accuracy        F1  \n",
       "0   0.695867  0.767013  \n",
       "1   0.695558  0.766722  \n",
       "2   0.695558  0.766722  \n",
       "3   0.695558  0.766722  \n",
       "4   0.695558  0.766722  \n",
       "5   0.695558  0.766722  \n",
       "6   0.685379  0.756911  \n",
       "7   0.689081  0.759312  \n",
       "8   0.689081  0.759312  \n",
       "9   0.689081  0.759312  \n",
       "10  0.689081  0.759312  \n",
       "11  0.689081  0.759312  \n",
       "12   0.69525  0.766541  \n",
       "13   0.69525   0.76643  \n",
       "14   0.69525   0.76643  \n",
       "15  0.690623  0.762379  \n",
       "16  0.694633  0.765847  \n",
       "17   0.69525   0.76643  \n",
       "18  0.683837  0.759784  \n",
       "19  0.683529  0.759606  \n",
       "20  0.683529  0.759606  \n",
       "21  0.683529  0.759606  \n",
       "22  0.683529  0.759606  \n",
       "23  0.683529  0.759606  \n",
       "24  0.681986  0.758943  \n",
       "25  0.681061  0.758185  \n",
       "26  0.681061  0.758185  \n",
       "27  0.681061  0.758185  \n",
       "28  0.681061  0.758185  \n",
       "29  0.681061  0.758185  \n",
       "30  0.681061  0.758185  \n",
       "31  0.681061  0.758185  \n",
       "32  0.681061  0.758185  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it appears that the model using newton-cg, none penalty, and c 1e40 works the best\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c9463265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve: 0.719\n",
      "Accuracy: 0.696\n",
      "F1 Score: 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleguillen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create Model using the best parameters\n",
    "clf = linear_model.LogisticRegression(C=1e40 , solver='newton-cg', penalty = 'none', random_state=4)\n",
    "fit_model = clf.fit(X_Data, Y_Data.values)\n",
    "auc = metrics.roc_auc_score(Y_Data.values, fit_model.predict_proba(X_Data)[:,1])\n",
    "acc = metrics.accuracy_score(Y_Data, fit_model.predict(X_Data))\n",
    "f1 = metrics.f1_score(Y_Data, fit_model.predict(X_Data))\n",
    "metrics.plot_roc_curve(clf,X_Data, Y_Data)\n",
    "print('Area Under Curve:', round(auc,3))\n",
    "print('Accuracy:', round(acc,3))\n",
    "print('F1 Score:', round(f1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4aae65",
   "metadata": {},
   "source": [
    "Display the Features importance ordered by most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f62e2fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age_s1', 'race', 'educat', 'mstat', 'hip', 'neck20', 'waist',\n",
      "       'av_weight_kg', 'cgpkyr', 'tea15', 'srhype', 'parrptdiab', 'bend25',\n",
      "       'happy25', 'tired25', 'hlthlm25'],\n",
      "      dtype='object')\n",
      "age_s1          0.007290\n",
      "race           -0.372387\n",
      "educat          0.183015\n",
      "mstat          -0.137113\n",
      "hip            -0.609560\n",
      "neck20         -0.185504\n",
      "waist           1.136628\n",
      "av_weight_kg   -0.235567\n",
      "cgpkyr          0.000386\n",
      "tea15          -0.066710\n",
      "srhype          0.072874\n",
      "parrptdiab      0.159858\n",
      "bend25          0.088405\n",
      "happy25        -0.083514\n",
      "tired25         0.117776\n",
      "hlthlm25       -0.363242\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>CoEfficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age_s1</th>\n",
       "      <td>age_s1</td>\n",
       "      <td>0.007290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>race</td>\n",
       "      <td>-0.372387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educat</th>\n",
       "      <td>educat</td>\n",
       "      <td>0.183015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mstat</th>\n",
       "      <td>mstat</td>\n",
       "      <td>-0.137113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hip</th>\n",
       "      <td>hip</td>\n",
       "      <td>-0.609560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neck20</th>\n",
       "      <td>neck20</td>\n",
       "      <td>-0.185504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waist</th>\n",
       "      <td>waist</td>\n",
       "      <td>1.136628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_weight_kg</th>\n",
       "      <td>av_weight_kg</td>\n",
       "      <td>-0.235567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cgpkyr</th>\n",
       "      <td>cgpkyr</td>\n",
       "      <td>0.000386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea15</th>\n",
       "      <td>tea15</td>\n",
       "      <td>-0.066710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srhype</th>\n",
       "      <td>srhype</td>\n",
       "      <td>0.072874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parrptdiab</th>\n",
       "      <td>parrptdiab</td>\n",
       "      <td>0.159858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bend25</th>\n",
       "      <td>bend25</td>\n",
       "      <td>0.088405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy25</th>\n",
       "      <td>happy25</td>\n",
       "      <td>-0.083514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tired25</th>\n",
       "      <td>tired25</td>\n",
       "      <td>0.117776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hlthlm25</th>\n",
       "      <td>hlthlm25</td>\n",
       "      <td>-0.363242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Features  CoEfficients\n",
       "age_s1              age_s1      0.007290\n",
       "race                  race     -0.372387\n",
       "educat              educat      0.183015\n",
       "mstat                mstat     -0.137113\n",
       "hip                    hip     -0.609560\n",
       "neck20              neck20     -0.185504\n",
       "waist                waist      1.136628\n",
       "av_weight_kg  av_weight_kg     -0.235567\n",
       "cgpkyr              cgpkyr      0.000386\n",
       "tea15                tea15     -0.066710\n",
       "srhype              srhype      0.072874\n",
       "parrptdiab      parrptdiab      0.159858\n",
       "bend25              bend25      0.088405\n",
       "happy25            happy25     -0.083514\n",
       "tired25            tired25      0.117776\n",
       "hlthlm25          hlthlm25     -0.363242"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefficients are given in the same order as the training data columns\n",
    "#https://datascience.stackexchange.com/questions/29131/feature-names-in-logisticregression\n",
    "#Normalize the coefficients\n",
    "print((X_Data.columns))\n",
    "print(np.std(X_Data,0)*fit_model.coef_[0])\n",
    "features = X_Data.columns\n",
    "Cofs = np.std(X_Data,0)*fit_model.coef_[0]\n",
    "CofDict = {'Features':features, 'CoEfficients':Cofs}\n",
    "COFdf = pd.DataFrame(CofDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "676f409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>CoEfficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>waist</th>\n",
       "      <td>waist</td>\n",
       "      <td>1.136628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hip</th>\n",
       "      <td>hip</td>\n",
       "      <td>-0.609560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>race</td>\n",
       "      <td>-0.372387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hlthlm25</th>\n",
       "      <td>hlthlm25</td>\n",
       "      <td>-0.363242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_weight_kg</th>\n",
       "      <td>av_weight_kg</td>\n",
       "      <td>-0.235567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neck20</th>\n",
       "      <td>neck20</td>\n",
       "      <td>-0.185504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educat</th>\n",
       "      <td>educat</td>\n",
       "      <td>0.183015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parrptdiab</th>\n",
       "      <td>parrptdiab</td>\n",
       "      <td>0.159858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mstat</th>\n",
       "      <td>mstat</td>\n",
       "      <td>-0.137113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tired25</th>\n",
       "      <td>tired25</td>\n",
       "      <td>0.117776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bend25</th>\n",
       "      <td>bend25</td>\n",
       "      <td>0.088405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy25</th>\n",
       "      <td>happy25</td>\n",
       "      <td>-0.083514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srhype</th>\n",
       "      <td>srhype</td>\n",
       "      <td>0.072874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea15</th>\n",
       "      <td>tea15</td>\n",
       "      <td>-0.066710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_s1</th>\n",
       "      <td>age_s1</td>\n",
       "      <td>0.007290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cgpkyr</th>\n",
       "      <td>cgpkyr</td>\n",
       "      <td>0.000386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Features  CoEfficients\n",
       "waist                waist      1.136628\n",
       "hip                    hip     -0.609560\n",
       "race                  race     -0.372387\n",
       "hlthlm25          hlthlm25     -0.363242\n",
       "av_weight_kg  av_weight_kg     -0.235567\n",
       "neck20              neck20     -0.185504\n",
       "educat              educat      0.183015\n",
       "parrptdiab      parrptdiab      0.159858\n",
       "mstat                mstat     -0.137113\n",
       "tired25            tired25      0.117776\n",
       "bend25              bend25      0.088405\n",
       "happy25            happy25     -0.083514\n",
       "srhype              srhype      0.072874\n",
       "tea15                tea15     -0.066710\n",
       "age_s1              age_s1      0.007290\n",
       "cgpkyr              cgpkyr      0.000386"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort by level of influence:\n",
    "COFdf.reindex(COFdf.CoEfficients.abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518aba97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
